{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ">>>***Preparation of python libraries***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VZQbxISoF9FC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (16, 9)\n",
        "plt.style.use('fast')\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten, LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.layers import Bidirectional\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "from numpy import *\n",
        "import keras.backend as K\n",
        "from keras.regularizers import l2"
      ],
      "metadata": {
        "id": "ljZR3J1ygvtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>>***INPUT DATA PROCESSING***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MCPmiae4GWR5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaQI7ABbEQWp"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('Name_of_the_file', index_col='Date')\n",
        "valores_nulos = df.isnull().sum()\n",
        "df = df.dropna()\n",
        "df.head() #Dataframe characteristics are shown\n",
        "#Chart parameters are defined, such as index labels, chart size, etc.\n",
        "df.plot(figsize=(15,10))\n",
        "plt.legend(fontsize=10)\n",
        "plt.xlabel('Year', fontsize=25)\n",
        "plt.ylabel('Price',fontsize=25)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The code is divided into train (80%: 70% for training and 10% for validation) and test (20)***"
      ],
      "metadata": {
        "id": "91dkIi2LW0lL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v=int(len(df))\n",
        "values = df.iloc[:v,-1].values\n",
        "values = values.astype('float32')\n",
        "values=values.reshape(-1, 1)\n",
        "n_train_days = int(len(df)*0.7)\n",
        "n_val_days=int(len(df)*0.1)\n",
        "n_test_days=int(len(df)*0.2)\n",
        "train = values[:n_train_days-n_val_days, :]\n",
        "validation= train[:n_val_days, :]\n",
        "test = values[n_train_days:, :]\n",
        "x_train, y_train = train[:, :-1], train[:, -1]\n",
        "x_val, y_val = test[:, :-1], test[:, -1]\n"
      ],
      "metadata": {
        "id": "SMQ4Fv6LEsxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** Data normalization***"
      ],
      "metadata": {
        "id": "W0nWol66X7Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe1=df.transpose()\n",
        "train_rate = 0.8 #Training rate will determine the learning level of the network\n",
        "seq_len = 25 #It will use a window of 25 data to make the prediction\n",
        "pre_len = 5 #It will launch 25 predictions for each of the time windows used\n",
        "num_nodes, time_len = dataframe1.shape\n",
        "#Data is normalized between [0,1]\n",
        "def train_test_split(data, train_portion):\n",
        "    time_len = data.shape[1]\n",
        "    train_size = int(time_len * train_portion)\n",
        "    train_data = np.array(data.iloc[:1, :n_train_days-n_val_days])\n",
        "    test_data = np.array(data.iloc[:1, n_train_days:])\n",
        "    val_data =  np.array(data.iloc[:1, n_train_days-n_val_days:n_train_days])\n",
        "    return train_data, test_data,val_data\n",
        "train_data, test_data, val_data = train_test_split(dataframe1, train_rate)\n",
        "def scale_data(train_data, test_data,val_data):\n",
        "    max_speed = train_data.max()\n",
        "    min_speed = train_data.min()\n",
        "    train_scaled = (train_data - min_speed) / (max_speed - min_speed)\n",
        "    test_scaled = (test_data - min_speed) / (max_speed - min_speed)\n",
        "    val_scaled = (val_data - min_speed) / (max_speed - min_speed)\n",
        "    return train_scaled, test_scaled,val_scaled\n",
        "train_scaled, test_scaled, val_scaled = scale_data(train_data, test_data,val_data)\n",
        "def sequence_data_preparation(seq_len, pre_len, train_data, test_data,val_data):\n",
        "    trainX, trainY, testX, testY, valY, valX = [], [], [], [], [], []\n",
        "\n",
        "    for i in range(train_data.shape[1] - int(seq_len + pre_len - 1)):\n",
        "        a = train_data[:, i : i + seq_len + pre_len]\n",
        "        trainX.append(a[:, :seq_len])\n",
        "        trainY.append(a[:, -1])\n",
        "\n",
        "    for i in range(test_data.shape[1] - int(seq_len + pre_len - 1)):\n",
        "        b = test_data[:, i : i + seq_len + pre_len]\n",
        "        testX.append(b[:, :seq_len])\n",
        "        testY.append(b[:, -1])\n",
        "\n",
        "    for i in range(val_data.shape[1] - int(seq_len + pre_len - 1)):\n",
        "        c = val_data[:, i : i + seq_len + pre_len]\n",
        "        valX.append(c[:, :seq_len])\n",
        "        valY.append(c[:, -1])\n",
        "\n",
        "    trainX = np.array(trainX)\n",
        "    trainY = np.array(trainY)\n",
        "    testX = np.array(testX)\n",
        "    testY = np.array(testY)\n",
        "    valX = np.array(valX)\n",
        "    valY = np.array(valY)\n",
        "\n",
        "    return trainX, trainY, testX, testY, valX, valY\n",
        "trainX, trainY, testX, testY, valX, valY = sequence_data_preparation(\n",
        "    seq_len, pre_len, train_scaled, test_scaled, val_scaled\n",
        ")"
      ],
      "metadata": {
        "id": "cbDvYASCF2Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">>>***MODEL GENERATION***"
      ],
      "metadata": {
        "id": "MAkclXvPGd4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_modeloFF():\n",
        "    model = Sequential()\n",
        "    PASOS=25\n",
        "    model.add(LSTM(units=25, input_shape=(1,PASOS), activation = \"tanh\", return_sequences = True))\n",
        "    model.add(LSTM(25, return_sequences = False, activation='tanh'))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(20, activation='tanh'))\n",
        "    model.add(Dense(1, activation='tanh'))\n",
        "    model.compile(loss='mean_absolute_error',optimizer='Adam',metrics=[\"mse\"])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "EPOCHS=100\n",
        "PASOS=25\n",
        "model = crear_modeloFF()\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=120,\n",
        "        verbose=1, mode='auto', restore_best_weights=True)\n",
        "\n",
        "history=model.fit(trainX,trainY,epochs=EPOCHS,callbacks=[monitor],validation_data=(valX,valY),batch_size=PASOS)\n"
      ],
      "metadata": {
        "id": "8prbUfejEzw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The results are rescaled and the graph is displayed***"
      ],
      "metadata": {
        "id": "HdPM8F-i0rS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df2 = pd.DataFrame(results)\n",
        "\n",
        "max_speed = train_data.max()\n",
        "min_speed = train_data.min()\n",
        "train_rescpred = np.array((testY) * max_speed)\n",
        "pred = np.array((results) * max_speed)\n",
        "pcompara = pd.DataFrame(np.array([[y[0] for y in train_rescpred], [x[0] for x in pred]])).transpose()\n",
        "\n",
        "\n",
        "pcompara.columns = ['real', 'prediccion']\n",
        "pcompara['diferencia'] = pcompara['real'] - pcompara['prediccion']\n",
        "pcompara.head()\n",
        "pcompara['real'].plot()\n",
        "pcompara['prediccion'].plot()\n",
        "#Results are saved in a CSV\n",
        "pcompara.to_csv('Name_of_the_file')\n",
        "\n"
      ],
      "metadata": {
        "id": "-quYjYDyE8fF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}